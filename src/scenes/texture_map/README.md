# Texture Map Scene

This scene demonstrates mapping 2D image textures onto the 3D LED model. The default image is the earth.

![digital globe](poster.png)

## Overview

The scene takes pre-processed image data stored in `texture_data.h` and projects it onto the surface of the 3D model based on the spherical coordinates of each LED point. This allows displaying images like maps, faces, or patterns wrapped around the model.

## Texture Data Generation

The texture data used by this scene is not part of the main source code but is generated by a Python script.

- **Source Images:** Place source images (e.g., `.png`, `.bmp`) inside the `src/scenes/texture_map/textures/` directory.
- **Generator Script:** The script `util/generate_props.py` processes these images.
- **Output:** The script generates the C++ header file `src/scenes/texture_map/textures/texture_data.h`.
- **Processing:**
    - Images are resized (maintaining aspect ratio) if they exceed the maximum resolution specified in the script (default is relatively small to manage memory).
    - Images are converted to RGB format.
    - Pixel data is stored as a flat `uint8_t` array (RGB, RGB, ...) in the header.
- **Compatibility:**
    - The generated header uses `PROGMEM` for storing the data arrays on platforms like Teensy to save RAM.
    - It includes conditional compilation (`#ifdef`/`#else`) to handle `PROGMEM` and the `pgm_read_byte` accessor, making it compatible with both hardware (AVR/Teensy) and the web simulator build (Emscripten).
- **Running the Generator:** To update or add new textures, run the script from the project root:
  ```bash
  python util/generate_props.py --images src/scenes/texture_map/textures
  ```
  (You might need to adjust the Python command based on your environment, e.g., `python3`).

## Texture Mapping Projection (Equirectangular)

The scene maps the 2D texture onto the 3D model points using a standard technique based on spherical coordinates, often called Equirectangular Projection:

1.  **Get 3D Point:** For each LED `i`, get its Cartesian coordinates (`x, y, z`) from `model().point(i)`.
2.  **Convert to Spherical Coordinates:**
    *   Calculate the distance from the origin (radius `r`).
    *   Calculate the **Azimuth** angle (`phi`) in the XY plane: `phi = atan2(y, x)`. This ranges from -π to +π.
    *   Calculate the **Inclination** (or polar) angle (`theta`) from the positive Z-axis: `theta = acos(z / r)`. This ranges from 0 to +π.
3.  **Normalize to UV Coordinates:** Map the spherical angles to 2D texture coordinates (U, V), each ranging from 0.0 to 1.0.
    *   `u = (phi + PI) / (2 * PI)` (Maps azimuth -π to +π onto U 0 to 1)
    *   `v = theta / PI` (Maps inclination 0 to +π onto V 0 to 1)
4.  **Map UV to Pixel Coordinates:** Convert the normalized UV coordinates to integer pixel coordinates (`texX`, `texY`) within the specific texture's dimensions.
    *   `texX = floor(u * texture_width)`
    *   `texY = floor(v * texture_height)`
5.  **Calculate Data Index:** Determine the starting index in the flat `texture_data` array corresponding to the `(texX, texY)` pixel.
    *   `index = (texY * texture_width + texX) * 3` (Multiply by 3 because each pixel has R, G, B components).
6.  **Read Pixel Data:** Fetch the R, G, and B values from the `texture_data` array using the platform-independent `pgm_read_byte` macro (defined conditionally in `texture_data.h`).
    *   `r = pgm_read_byte(&texture_data[index + 0]);`
    *   `g = pgm_read_byte(&texture_data[index + 1]);`
    *   `b = pgm_read_byte(&texture_data[index + 2]);`
7.  **Set LED Color:** Assign the retrieved color to the current LED: `leds[i] = PixelTheater::CRGB(r, g, b);`

This process effectively wraps the 2D image around the 3D model. 